---
title: "NLS confidence intervals"
author: "Ethann Barnes"
date: "5/2/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library(ggplot2)

samples<-read.csv("competition_sampling.csv", header = TRUE, na.strings = ".")
samples$YL<-(samples$YL*100)
samples$yr_repl  <- with(samples, factor(year):factor(rep))
samples<-subset(samples, trt > 1)
```
## Below creates a function that bootstraps NLS. Don't change any of this! New function is called predictNLS
```{r}
predictNLS <- function(
object, 
newdata,
level = 0.95, 
nsim = 10000,
...
)
{
  require(MASS, quietly = TRUE)
   
  ## get right-hand side of formula
  RHS <- as.list(object$call$formula)[[3]]
  EXPR <- as.expression(RHS)
   
  ## all variables in model
  VARS <- all.vars(EXPR)
   
  ## coefficients
  COEF <- coef(object)
   
  ## extract predictor variable    
  predNAME <- setdiff(VARS, names(COEF))  
   
  ## take fitted values, if 'newdata' is missing
  if (missing(newdata)) {
    newdata <- eval(object$data)[predNAME]
    colnames(newdata) <- predNAME
  }
     
  ## check that 'newdata' has same name as predVAR
  if (names(newdata)[1] != predNAME) stop("newdata should have name '", predNAME, "'!")
   
  ## get parameter coefficients
  COEF <- coef(object)
     
  ## get variance-covariance matrix
  VCOV <- vcov(object)
   
  ## augment variance-covariance matrix for 'mvrnorm' 
  ## by adding a column/row for 'error in x'
  NCOL <- ncol(VCOV)
  ADD1 <- c(rep(0, NCOL))
  ADD1 <- matrix(ADD1, ncol = 1)
  colnames(ADD1) <- predNAME
  VCOV <- cbind(VCOV, ADD1)
  ADD2 <- c(rep(0, NCOL + 1))
  ADD2 <- matrix(ADD2, nrow = 1)
  rownames(ADD2) <- predNAME
  VCOV <- rbind(VCOV, ADD2) 
         
  ## iterate over all entries in 'newdata' as in usual 'predict.' functions
  NR <- nrow(newdata)
  respVEC <- numeric(NR)
  seVEC <- numeric(NR)
  varPLACE <- ncol(VCOV)   
   
  ## define counter function
  counter <- function (i) 
  {
    if (i%%10 == 0) 
      cat(i)
    else cat(".")
    if (i%%50 == 0) 
      cat("\n")
    flush.console()
  }
   
  outMAT <- NULL 
   
  for (i in 1:NR) {
    counter(i)
     
    ## get predictor values and optional errors
    predVAL <- newdata[i, 1]
    if (ncol(newdata) == 2) predERROR <- newdata[i, 2] else predERROR <- 0
    names(predVAL) <- predNAME  
    names(predERROR) <- predNAME  
     
    ## create mean vector for 'mvrnorm'
    MU <- c(COEF, predVAL)
     
    ## create variance-covariance matrix for 'mvrnorm'
    ## by putting error^2 in lower-right position of VCOV
    newVCOV <- VCOV
    newVCOV[varPLACE, varPLACE] <- predERROR^2
     
    ## create MC simulation matrix
    simMAT <- mvrnorm(n = nsim, mu = MU, Sigma = newVCOV, empirical = TRUE)
     
    ## evaluate expression on rows of simMAT
    EVAL <- try(eval(EXPR, envir = as.data.frame(simMAT)), silent = TRUE)
    if (inherits(EVAL, "try-error")) stop("There was an error evaluating the simulations!")
     
    ## collect statistics
    PRED <- data.frame(predVAL)
    colnames(PRED) <- predNAME   
    FITTED <- predict(object, newdata = data.frame(PRED))
    MEAN.sim <- mean(EVAL, na.rm = TRUE)
    SD.sim <- sd(EVAL, na.rm = TRUE)
    MEDIAN.sim <- median(EVAL, na.rm = TRUE)
    MAD.sim <- mad(EVAL, na.rm = TRUE)
    QUANT <- quantile(EVAL, c((1 - level)/2, level + (1 - level)/2))
    RES <- c(FITTED, MEAN.sim, SD.sim, MEDIAN.sim, MAD.sim, QUANT[1], QUANT[2])
    outMAT <- rbind(outMAT, RES)
  }
   
  colnames(outMAT) <- c("fit", "mean", "sd", "median", "mad", names(QUANT[1]), names(QUANT[2]))
  rownames(outMAT) <- NULL
   
  cat("\n")
   
  return(outMAT)  
}
```

## Everything else is outlined here.
```{r}
#Normal nls function with Cousens model. YL (yield loss) is the Y variable, l.LAI.rag (Leaf area index of ragweed at the last sampling) is the X variable. 
l.LAI<-nls(YL~(I*l.LAI.rag)/(1+(I*l.LAI.rag)/A), data = samples, start = list(I=100, A=100), control = list(maxiter = 500), algorithm = "port", upper = c(100000,100))

#Create a new data frame with X values. In this case I created X values from 0 to 5.5 LAI increasing by every 0.01.
nd5 = data.frame(l.LAI.rag=seq(0, 5.5, .01))

#Use new funciton, predictNLS, to created confidence interval (This can take a few minutes to compute). This function returns many of the original NLS values which is needed for ploting easily.
# So, l.LAI is the NLS model we are fitting and nd5 is the new dataframe we made with just X values.
pred.top<-predictNLS(l.LAI, nd5)
pred.top<-as.data.frame(pred.top)

# This adds the X values created so that you can plot later.
pred.top$l.LAI.rag<-nd5$l.LAI.rag

# fit is the Y variable same as the original NLS model
pred.top$YL<-pred.top$fit

#create new name for upper limit
pred.top$upr<-pred.top$`97.5%`

#same for lower limit
pred.top$lwr<-pred.top$`2.5%`
pred.top<-as.data.frame(pred.top)

# Delete any upper limits greater than the maximum you want the y-axis to go to. I did'nt want my y-axis to go above 100% yield loss so I deleted any upper limits greater than 100.
pred.top$upr2<-ifelse(pred.top$upr>100.0000000,100,pred.top$upr)

# use original data file for plotting data points.
  Figure_Maxwel<-ggplot(data=samples, aes(x=l.LAI.rag, y=YL)) + geom_point(aes(shape=factor(year))) +
# use new data file for [plotting fitted nls line and confidence interval
  geom_line(data=pred.top, aes(y=YL, x=l.LAI.rag),size=1) +
  geom_ribbon(data=pred.top, aes(ymin=lwr, ymax=upr2), alpha=0.25) +
 
# just aesthetics adjustments 
    scale_x_continuous("Common ragweed LAI at R6 stage", expand = c(0,0)) +
  scale_y_continuous("Soybean yield loss (%)", limits = c(0,100), expand = c(0,0)) +
  scale_shape_discrete(name="  Year") +
  theme_bw(base_size = 18) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA)) + theme(legend.position=c(.90,.10))

# save figure as tif
  tiff("Figure_Maxwel.tif", width = 18.415, height = 18.415, units = 'cm', res=300)
  Figure_Maxwel
  dev.off()
```
